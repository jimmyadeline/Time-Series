---
title: "STAT 621 HW 4"
author: "Yingying Xu"
date: "2/19/2018 (Due)"
output: pdf_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 1 

Consider the following AR(4) process: $y_t=4+0.5y_{t-4}+w_t$ where $w_t\sim WN(0,2)$. PAY ATTENTION to the "lag" and notice that the mean is not zero.  For several of these questions, you have done similar problems before. This will serve as a good review. 
$$
y_t=4+0.5y_{t-4}+w_t
$$


### a. (10) Derive the MA(infinity) form of the model by "hand".

$$
y_t =4+0.5y_{t-4}+w_t=4+0.5(4+0.5y_{t-8}+w_{t-4})+w_t 
$$
$$
=4(1+0.5+0.5^2+...)+w_t+0.5w_{t-4}+0.5^2w_{t-8}+...
$$
$$
=4\sum^{\infty}_{j=0}0.5^j+\sum^{\infty}_{j=0}0.5^jw_{t-4j}
$$

### b. (5) Verify that you obtain the same coefficients by using the ARMA to MA command in R. Plot these coefficients using R. 

```{r}
plot(ARMAtoMA(ar=c(0,0,0,0.5), lag.max = 50))
```

### c. (5) Derive the mean of the process. 
$$
E(y_t)=E[4(1+0.5+0.5^2+...)+w_t+0.5w_{t-4}+0.5^2w_{t-8}+...]=4(1+0.5+0.5^2+...)
$$

where $1+0.5+0.5^2+...=\frac{2^{n-1}-1}{2^{n-1}}$. For n goes to infinity, $\sum^\infty_{j=0}x^j=1/(1-x)$ when $|x|<1$. Therefore, $E(y_t)=4*1/(1-0.5)=8$

### d. (5) Derive the variance of the process.
$$
Var(y_t)=Var(w_t+0.5w_{t-4}+0.5^2w_{t-8}...)=(1+0.25+0.25^2+...)\sigma^2_w=1/(1-0.25)*\sigma^2_w=8/3
$$

### e. (5) Derive the autocorrelation function of the process. 

$$
\rho(h)=\gamma(h)/\gamma(0)=\gamma(h)/Var(y_t)
$$
$$
\gamma(h)=0 \quad \textrm{if} \quad h=1,2,3,5,6,7,9... \textrm{(not divisible by 4)}
$$
$$
\gamma(4)=0.5\sigma^2_w+0.5^3\sigma^2_w+0.5^5\sigma^2_w+...=0.5(1+0.25+0.25^2+...)\sigma^2_w
$$
$$
\gamma(8)=0.5^2\sigma^2_w+0.5^4\sigma^2_w+0.5^6\sigma^2_w+...=0.5^2(1+0.25+0.25^2+...)\sigma^2_w
$$
$$
\gamma(h)=0.5^{h/4}(1+0.25+0.25^2+...)\sigma^2_w \quad \textrm{if} \quad h=0,4,8,12...\textrm{(divisible by 4)}
$$

Therefore, $\rho(h)=\gamma(h)/\gamma(0)=0.5^{h/4}$ if h is divisible by 4 and $\rho(h)=0$ for else. Same as the plot in question b).

### f. (5) State the PACF of the process (you can use R to discover the function if the function is not obvious to you). 
The PACF is 0 after lag(4) and also be zero for lag(1) lag(2) and lag(3).

### g. (5) Is the process a stationary causal autoregressive model? Why or why not?

$1-0.5z^4=0$ then $z=\sqrt{\sqrt{2}}>1$ it is causal. 


### h. (5) Simulate a series of length 300 from the AR model and plot the series, a histogram, and the ACF and PACF of the series. 

```{r}
set.seed(1001)
y=arima.sim(list(order=c(4,0,0),ar=c(0,0,0,0.5)),sd = sqrt(2),n=300)


par(mfrow=c(3,1),mar=c(2.5,2.5,0,0)+.5,mgp=c(1.6,.6,0))
plot(y)
acf(y)
pacf(y)
```

### i. (5) Comment on what you have learned. Can you think of an example case-study for which this model might be appropriate?
The PACF of AR(p) is around 0 after lag p and the ACF decay exponentially. If there is gap between $x_t$ and $x_{t-p}$, then ACF and PACF will be zero for whatever in between. 


# Question 2 # 3.1

$$
x_t=w_t+\theta w_{t-1}
$$

$E[x_t]=0$. $Var(x_t)=(1+\theta^2)\sigma^2_w=\gamma(0)$. 
The Autocovariance $\gamma(h)=\theta\sigma^2_w$ if $h=\pm1$ and $\gamma(h)=0$ if $|h|>1$.
The autocorrelation $\rho(h)=\theta/(1+\theta^2)$ if $h=1$ and $\rho(h)=0$ if $|h|>1$.

$$
\rho(1)=\theta/(1+\theta^2)=1/(1/\theta+\theta) \quad \textrm{where} \quad |1/\theta+\theta|\geq 2
$$
Therefore, $|\rho(1)|\leq 1/2$. The maximum $\rho(1)=1/2$ when $\theta=1$; the minimum $\rho(1)=-1/2$ when $\theta=-1$.


# Question 3 # 3.4 Identify as ARMA(p,q) models (causal/invertible)

### a)
$$
x_t=0.8x_{t-1}-0.15x_{t-2}+w_t-0.3w_{t-1}
$$
$$
(1-0.8B+0.15B^2)x_t=(1-0.3B)w_t \Rightarrow (1-0.5B)(1-0.3B)x_t=(1-0.3B)w_t \Rightarrow (1-0.5B)x_t=w_t \Rightarrow x_t=0.5x_{t-1}+w_t 
$$

Causal: $1-0.5z=0 \Rightarrow z=2>1$ it is causal.

No lag of $w_t$ so it is not invertible.

### b)

$$
x_t=x_{t-1}-0.5x_{t-2}+w_t-w_{t-1} \Rightarrow (1-B+0.5B^2)x_t=(1-B)w_t
$$

Causal: 
$$
1-z+0.5z^2=0 \Rightarrow z=1\pm i \Rightarrow |z|=\sqrt{1^2+i^2}=1.414>1
$$ 
It is causal.

Not Invertible: $1-z=0 \Rightarrow z=1$ is not outside the unit circle. It is not invertible.

# Question 4 # 3.6 AR(2) autoregressive polynomial and ACF
$$
x_t=-0.9x_{t-2}+w_t=(-0.9)^2x_{t-4}-0.9w_{t-2}+w_t=\sum^{\infty}_{j=0}(-0.9)^jw_{t-2j}
$$
$$
\Phi(B)x_t=(1+0.9B^2)x_t=w_t
$$

$\Phi(B)$ is the characteristic polynomial of the process. $1+0.9z^2=0$ we got complex roots. $z=\pm \frac{\sqrt{-0.9}}{0.9}=\pm \frac{i}{\sqrt{0.9}}$. It is causal. 

$$
Autocovariance \quad \gamma(0)=(1+0.81+0.81^2+...)\sigma^2_w=1/(1-0.81)\sigma^2_w
$$
$$
Autocovariance \quad \gamma(2)=(-0.9)*(1+0.81+0.81^2+...)\sigma^2_w=-0.9/(1-0.81)\sigma^2_w
$$
$$
Autocovariance \quad \gamma(h)=(-0.9)^{h/2}/(1-0.81)\sigma^2_w \quad \textrm{(h is divisible by 2)}
$$
$$
Autocorrelation \quad \rho(h)=(-0.9)^{h/2} \quad \textrm{(for h is divisible by 2)}
$$
$\rho(h)=0$ otherwise.

```{r}
ARMAtoMA(ar=c(0,-0.9), lag.max = 10)
```
```{r}
plot(ARMAtoMA(ar=c(0,-0.9), lag.max = 50))
```

# Question 5 # 3.9 
$$
ARMA(1,1) \quad x_t=\phi x_{t-1}+\theta w_{t-1}+w_t=0.6 x_{t-1}+0.9 w_{t-1}+w_t
$$
$$
AR(1) \quad x_t=0.6x_{t-1}+w_t=\sum^{\infty}_{j=0}0.6^jw_{t-j}
$$

$$
MA(1) \quad x_t=0.9w_{t-1}+w_t
$$

```{r}
x1=arima.sim(list(order=c(1,0,1),ar=0.6,ma=0.9),n=100)
x2=arima.sim(list(order=c(1,0,0),ar=0.6),n=100)
x3=arima.sim(list(order=c(0,0,1),ma=0.9),n=100)

par(mfrow=c(3,1),mar=c(2.5,2.5,0,0)+.5,mgp=c(1.6,.6,0))
acf(x1,48,ylab="ARMA(1,1)")
acf(x2,48,ylab="AR(1)")
acf(x3,48,ylab="MA(1)")
```

For ARMA(1,1), ACF exponentially decay.
For AR(1), ACF decay exponentially after lag(1); Theoretically, $\rho(0)=1; \rho(1)=0.6; \rho(h)=0.6^h$
For MA(1), ACF is zero after lag(1). Theoretically, $\rho(0)=1; \rho(1)=0.9/(1+0.81)\approx 0.5; rho(h)=0, else$

```{r}
par(mfrow=c(3,1),mar=c(2.5,2.5,0,0)+.5,mgp=c(1.6,.6,0))
pacf(x1,ylab="ARMA(1,1)")
pacf(x2,ylab="AR(1)")
pacf(x3,ylab="MA(1)")
```

For ARMA(1,1), PACF exponentially decay; For AR(1), PACF is zero after lag(1); For MA(1), PACF decay exponentially after lag(1).